{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import hashlib\n",
    "\n",
    "data_path = '../../analysis/pre'\n",
    "\n",
    "def site_id_hash(site_id):\n",
    "    sha256_hash = hashlib.sha256(site_id.encode()).hexdigest()\n",
    "    return sha256_hash[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative sites data loaded\n",
      "Power data length: 1277529\n"
     ]
    }
   ],
   "source": [
    "# Get all data of alternative sites\n",
    "\n",
    "site_info_alt = pd.read_csv(data_path + '/data-fetching/alternative-sites/site_info_20230101.csv')\n",
    "weather_data_alt = pd.read_csv(data_path + '/data-fetching/alternative-sites/df_weather-20230101-20240501.csv')\n",
    "\n",
    "weather_data_alt.rename(columns={'ts': 'time'}, inplace=True)\n",
    "weather_data_alt['time'] = pd.to_datetime(weather_data_alt['time'])\n",
    "\n",
    "power_data_alt = pd.DataFrame()\n",
    "\n",
    "temp_site_info = []\n",
    "\n",
    "for index, row in site_info_alt.iterrows():\n",
    "    site = row\n",
    "    cluster = 0 # cluster 0 is chosen (= no clustering)\n",
    "    site_id = site['site_id']\n",
    "    new_entry = {\n",
    "        'site_id': site_id, \n",
    "        'cluster': cluster,\n",
    "        'lat': 0, # site['lat'],\n",
    "        'lng': 0, # site['lng'],\n",
    "        'zip': site['zip'],\n",
    "        'country': site['country'],\n",
    "        'kwp': site['kwp'],\n",
    "    }\n",
    "    temp_site_info.append(new_entry)\n",
    "    site_power_data = pd.read_csv(data_path + f'/data-fetching/alternative-sites/df_{site_id}-20230101-20240501.csv')\n",
    "    power_data_alt = pd.concat([power_data_alt, site_power_data])\n",
    "\n",
    "site_info_alt = pd.DataFrame(temp_site_info)\n",
    "power_data_alt['time'] = pd.to_datetime(power_data_alt['time'])\n",
    "\n",
    "print('Alternative sites data loaded')\n",
    "print(f'Power data length: {len(power_data_alt)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main sites data loaded\n",
      "Power data length: 878496\n"
     ]
    }
   ],
   "source": [
    "# Get all data of main sites\n",
    "\n",
    "site_info = pd.read_csv(data_path + '/data-fetching/site_info_20230101.csv')\n",
    "weather_data = pd.read_csv(data_path + '/data-fetching/df_weather-20230101-20240101.csv')\n",
    "clusters = pd.read_csv(data_path + '/site-clustering//closest_sites.csv')\n",
    "\n",
    "weather_data.rename(columns={'ts': 'time'}, inplace=True)\n",
    "weather_data['time'] = pd.to_datetime(weather_data['time'])\n",
    "\n",
    "power_data = pd.DataFrame()\n",
    "\n",
    "temp_site_info = []\n",
    "\n",
    "for index, row in site_info.iterrows():\n",
    "    site = row\n",
    "    cluster = clusters[clusters['site_id'] == site['site_id']].iloc[0]\n",
    "    site_id = site['site_id']\n",
    "    new_entry = {\n",
    "        'site_id': site_id, \n",
    "        'cluster': cluster['cluster'],\n",
    "        'lat': 0, # site['lat'],\n",
    "        'lng': 0, # site['lng'],\n",
    "        'zip': site['zip'],\n",
    "        'country': site['country'],\n",
    "        'kwp': site['kwp'],\n",
    "    }\n",
    "    temp_site_info.append(new_entry)\n",
    "    site_power_data = pd.read_csv(data_path + f'/data-fetching/df_{site_id}-20230101-20240101.csv')\n",
    "    power_data = pd.concat([power_data, site_power_data])\n",
    "\n",
    "site_info = pd.DataFrame(temp_site_info)\n",
    "power_data['time'] = pd.to_datetime(power_data['time'])\n",
    "\n",
    "print('Main sites data loaded')\n",
    "print(f'Power data length: {len(power_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat alternative and main sites\n",
    "site_info = pd.concat([site_info, site_info_alt], ignore_index=True)\n",
    "power_data = pd.concat([power_data, power_data_alt], ignore_index=True)\n",
    "weather_data = pd.concat([weather_data, weather_data_alt], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data loaded\n",
      "Site info length: 30\n",
      "Power data length: 2156025\n",
      "Weather data length: 239526\n",
      "                                 site_id  cluster  lat  lng    zip country  \\\n",
      "0   0106fa6a-06d7-4991-a254-93d4ee1464a3        0    0    0   4073      AT   \n",
      "1   1df9e630-c947-4b9a-89e2-c77b643506c5        1    0    0   1220      AT   \n",
      "2   2bbfa73e-2a2e-473b-8d1c-f6b87bff8403        7    0    0   8055      AT   \n",
      "3   50eb6cac-7dbb-44ae-83c6-9b4879a57425        7    0    0   8401      AT   \n",
      "4   6045bd8d-1754-4963-b3cb-c703110ac5ac        0    0    0   4100      AT   \n",
      "5   60f50416-f2b0-4191-b82d-c71ba439d558        7    0    0   8041      AT   \n",
      "6   70118ad9-4de9-473e-8415-27e5f641a7a1        1    0    0   1220      AT   \n",
      "7   98e065ed-de0e-4973-8e43-7020defe23b0        1    0    0   1220      AT   \n",
      "8   a62e58d7-8b9a-4531-9ca5-323d136dcec0        0    0    0   4073      AT   \n",
      "9   a7b10e3f-e8a6-4f58-affd-c50b5f2c4201        7    0    0   8054      AT   \n",
      "10  aa13d3f3-04b2-43d1-b9ba-16adf87a4bc5        0    0    0   4073      AT   \n",
      "11  ba7b379a-829d-41cc-bc5d-04eeef3c5020        0    0    0   4072      AT   \n",
      "12  c8bf65f6-9940-4c65-8ff3-eac19451b1e3        1    0    0   1220      AT   \n",
      "13  e95b797d-3287-4eaa-b80a-771e840e2d83        7    0    0   8073      AT   \n",
      "14  ef5b7b47-37d4-4011-8b9f-fffd3020b0d9        1    0    0   1220      AT   \n",
      "15  018daa06-e6f7-4551-b32c-1a41fc8e0781        0    0    0  49685      DE   \n",
      "16  13d3ac14-1ba1-4271-bf0f-39e219b97aca        0    0    0   8625      AT   \n",
      "17  1530d0df-759c-482f-9450-c5e079fbc7ef        0    0    0   1190      AT   \n",
      "18  189043c3-35bd-43f9-9ca7-0136c10ea23d        0    0    0   4161      AT   \n",
      "19  19ee674c-fda3-45ee-90b2-8a4c8711459b        0    0    0   8472      CH   \n",
      "20  3024016a-4586-4f6a-b855-69ef7b91b140        0    0    0   5242      CH   \n",
      "21  30affaa5-128f-4068-95fb-efd40ea860b5        0    0    0   4761      AT   \n",
      "22  5767ef9c-25e9-47d2-8249-e044a29e0458        0    0    0  61350      DE   \n",
      "23  88ff6cd9-f81f-42e5-ad6c-b0ce7fc217bb        0    0    0  94034      DE   \n",
      "24  8b806cdc-8360-425d-a70d-d2d666097d3e        0    0    0   2483      AT   \n",
      "25  947c1748-df07-4ff8-845b-073e7ac8eeb9        0    0    0   9542      AT   \n",
      "26  a2d30421-5731-435a-b7ba-03d37ff0e0ce        0    0    0   9220      AT   \n",
      "27  ad5085d3-c72a-4a63-bf4f-56cb767b4633        0    0    0   8490      AT   \n",
      "28  b8c3d9bf-c225-44d3-a64f-11adb3aa0351        0    0    0   8665      AT   \n",
      "29  d34f66ce-a330-44f1-a8a6-b04e030ffff1        0    0    0  21641      DE   \n",
      "\n",
      "      kwp  \n",
      "0    16.0  \n",
      "1    15.0  \n",
      "2    10.0  \n",
      "3    10.0  \n",
      "4    10.0  \n",
      "5    10.0  \n",
      "6     0.0  \n",
      "7    10.0  \n",
      "8    10.0  \n",
      "9     0.0  \n",
      "10   10.0  \n",
      "11   40.0  \n",
      "12   10.0  \n",
      "13   20.0  \n",
      "14    8.0  \n",
      "15   13.0  \n",
      "16   25.0  \n",
      "17   10.0  \n",
      "18   10.0  \n",
      "19   20.0  \n",
      "20   80.0  \n",
      "21   30.0  \n",
      "22   15.0  \n",
      "23    9.6  \n",
      "24   10.0  \n",
      "25   10.0  \n",
      "26  194.0  \n",
      "27   22.0  \n",
      "28   10.0  \n",
      "29   10.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('All data loaded')\n",
    "print(f'Site info length: {len(site_info)}')\n",
    "print(f'Power data length: {len(power_data)}')\n",
    "print(f'Weather data length: {len(weather_data)}')\n",
    "\n",
    "print(site_info)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site ID: 0106fa6a-06d7-4991-a254-93d4ee1464a3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/35/hfsjshqn6zxgxjhjt_p2s4hw0000gp/T/ipykernel_1438/724645186.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  power_data_site['time'] = pd.to_datetime(power_data_site['time'])\n",
      "/var/folders/35/hfsjshqn6zxgxjhjt_p2s4hw0000gp/T/ipykernel_1438/724645186.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_data_site['time'] = pd.to_datetime(weather_data_site['time'])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# get row 1h and 2h before\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     row_1h \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m row[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimedelta(hours\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue_key\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m row[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue_key\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n\u001b[0;32m---> 50\u001b[0m     row_2h \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTimedelta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhours\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue_key\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue_key\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# set values if data is available\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(row_1h) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:4093\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[1;32m   4092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 4093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4095\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[1;32m   4096\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[1;32m   4097\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:4155\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   4154\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 4155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4142\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   4143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   4144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4145\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   4146\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4151\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4154\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   4155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4128\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[1;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4131\u001b[0m     )\n\u001b[0;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4140\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[1;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/managers.py:687\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    681\u001b[0m         indexer,\n\u001b[1;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[1;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    688\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[1;32m    689\u001b[0m             indexer,\n\u001b[1;32m    690\u001b[0m             axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    691\u001b[0m             fill_value\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    692\u001b[0m                 fill_value \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[1;32m    693\u001b[0m             ),\n\u001b[1;32m    694\u001b[0m         )\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    696\u001b[0m     ]\n\u001b[1;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/managers.py:688\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    681\u001b[0m         indexer,\n\u001b[1;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[1;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 688\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    696\u001b[0m     ]\n\u001b[1;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[0;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/array_algos/take.py:104\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;66;03m# EA.take is strict about returning a new object of the same type\u001b[39;00m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;66;03m# so for that case cast upfront\u001b[39;00m\n\u001b[1;32m    102\u001b[0m         arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(dtype)\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray,\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# includes for EA to catch DatetimeArray, TimedeltaArray\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_1d_only_ea_dtype(arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;66;03m# i.e. DatetimeArray, TimedeltaArray\u001b[39;00m\n\u001b[1;32m    109\u001b[0m         arr \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNDArrayBackedExtensionArray\u001b[39m\u001b[38;5;124m\"\u001b[39m, arr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.makedirs(f'../test_data', exist_ok=True)\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "\n",
    "for site_id in site_info['site_id']:\n",
    "    print(\"Site ID:\", site_id)\n",
    "    site = site_info[site_info['site_id'] == site_id].iloc[0]\n",
    "    power_data_site = power_data[(power_data['site_id'] == site_id)]\n",
    "    weather_data_site = weather_data[(weather_data['zip'] == site['zip'])]\n",
    "    \n",
    "    power_data_site['time'] = pd.to_datetime(power_data_site['time'])\n",
    "    weather_data_site['time'] = pd.to_datetime(weather_data_site['time'])\n",
    "\n",
    "    power_data_site = power_data_site.sort_values('time')\n",
    "\n",
    "\n",
    "    if len(weather_data_site) != 0:\n",
    "        weather_data_site = weather_data_site.sort_values('time')\n",
    "\n",
    "        duplicated_weather = []\n",
    "\n",
    "        # Duplicate weather data to match the power data\n",
    "        for index, row in weather_data_site.iterrows():\n",
    "            # Convert timestamp to datetime object\n",
    "            ts = row['time']\n",
    "            # Append the original row to the duplicated list\n",
    "            duplicated_weather.append(row)\n",
    "            # Duplicate the row for three additional times (15-minute intervals)\n",
    "            for _ in range(3):\n",
    "                ts += pd.Timedelta(minutes=15)\n",
    "                # Create a copy of the row and update the timestamp\n",
    "                new_row = row.copy()\n",
    "                new_row['time'] = ts\n",
    "                # Append the duplicated row to the list\n",
    "                duplicated_weather.append(new_row)\n",
    "        \n",
    "        generated_weather = pd.DataFrame(duplicated_weather)\n",
    "        generated_weather['site_id'] = site_id\n",
    "        power_data_site['site_id'] = site_id\n",
    "\n",
    "        df = pd.merge(generated_weather, power_data_site, on=['site_id', 'time'])\n",
    "\n",
    "        df = df[['time', 'site_id', 'value_key', 'avg', 'solar_rad', 'temp', 'precip', 'rh', 'ghi', 'snow_depth']]\n",
    "\n",
    "\n",
    "        weather_columns = ['solar_rad', 'temp', 'precip', 'rh', 'ghi', 'snow_depth']\n",
    "        for row in df.iterrows():\n",
    "            # get row 1h and 2h before\n",
    "            row_1h = df[(df['time'] == row[1]['time'] - pd.Timedelta(hours=1)) & (df['value_key'] == row[1]['value_key'])]\n",
    "            row_2h = df[(df['time'] == row[1]['time'] - pd.Timedelta(hours=1)) & (df['value_key'] == row[1]['value_key'])]\n",
    "            \n",
    "            # set values if data is available\n",
    "            if len(row_1h) != 0:\n",
    "                for column in weather_columns:\n",
    "                    df.loc[row[0], f'{column}_1h'] = row_1h[column].values[0]\n",
    "            else:\n",
    "                for column in weather_columns:\n",
    "                    df.loc[row[0], f'{column}_1h'] = np.nan\n",
    "\n",
    "            if len(row_2h) != 0:\n",
    "                for column in weather_columns:\n",
    "                    df.loc[row[0], f'{column}_2h'] = row_2h[column].values[0]\n",
    "            else:\n",
    "                for column in weather_columns:\n",
    "                    df.loc[row[0], f'{column}_2h'] = np.nan\n",
    "\n",
    "        site['weather_data'] = True\n",
    "    else:\n",
    "        df = df[['time', 'site_id', 'value_key', 'avg']]\n",
    "        site['weather_data'] = False\n",
    "    \n",
    "\n",
    "    df.sort_values('time', inplace=True)\n",
    "\n",
    "    for row in df.iterrows():\n",
    "        row_24h = df[(df['time'] == row[1]['time'] - pd.Timedelta(hours=24)) & (df['value_key'] == row[1]['value_key'])]\n",
    "\n",
    "        if len(row_24h) != 0:\n",
    "            df.loc[row[0], 'avg_24h'] = row_24h['avg'].values[0]\n",
    "        else:\n",
    "            df.loc[row[0], 'avg_24h'] = np.nan\n",
    "\n",
    "\n",
    "    os.makedirs(f'../data/test_data/{site_id}', exist_ok=True)\n",
    "    distinct_value_keys = df['value_key'].unique()\n",
    "    for value_key in distinct_value_keys:\n",
    "        filtered_df = df[df['value_key'] == value_key]\n",
    "        filtered_df.to_csv(f'../data/test_data/{site_id}/{value_key}.csv', index=False)\n",
    "\n",
    "    df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "    site_info.loc[site_info['site_id'] == site_id, 'weather_data'] = site['weather_data']\n",
    "\n",
    "    # create directories recursively\n",
    "    os.makedirs(f'../data/test_data/{site_id}', exist_ok=True)\n",
    "\n",
    "    site.to_csv(f'../data/test_data/{site_id}/site_info.csv', index=True)\n",
    "\n",
    "site_info.to_csv(f'../data/test_data/site_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 7  # The size of each window (in days)\n",
    "\n",
    "def are_subsequent(dates):\n",
    "    \"\"\"Check if dates are subsequent.\"\"\"\n",
    "    return np.all(np.diff(dates) == pd.Timedelta(days=1))\n",
    "\n",
    "for site_id in site_info['site_id']:\n",
    "    site = site_info[site_info['site_id'] == site_id].iloc[0]\n",
    "    site_power_data = power_data[(power_data['site_id'] == site_id)]\n",
    "\n",
    "    unique_days = np.sort(site_power_data['time'].dt.date.unique())\n",
    "\n",
    "    # Split the unique days into windows\n",
    "    windows = [unique_days[i:i+window_size] for i in range(0, len(unique_days), window_size)]\n",
    "\n",
    "    # Filter out non-subsequent windows\n",
    "    complete_windows = [window for window in windows if len(window) == window_size and are_subsequent(window)]\n",
    "\n",
    "    # Shuffle the windows\n",
    "    random.shuffle(complete_windows)\n",
    "\n",
    "    # Select a fixed number of windows for testing\n",
    "    test_windows_size = 4  # Change this to the number of windows you want for testing\n",
    "    test_windows, training_windows = complete_windows[:test_windows_size], complete_windows[test_windows_size:]\n",
    "\n",
    "    # Sort the windows\n",
    "    test_windows.sort(key=lambda x: x[0])\n",
    "    training_windows.sort(key=lambda x: x[0])\n",
    "\n",
    "    # Convert windows into DataFrame\n",
    "    training_windows_df = pd.DataFrame(training_windows)\n",
    "    test_windows_df = pd.DataFrame(test_windows)\n",
    "\n",
    "    # Write windows to CSV files\n",
    "    training_windows_df.to_csv(f'../data/test_data/{site_id}/training_windows.csv', index=False, header=True)\n",
    "    test_windows_df.to_csv(f'../data/test_data/{site_id}/test_windows.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max solar_rad: 956.2\n",
      "Max ghi: 956.21\n",
      "Max temp: 35.1\n",
      "Max precip: 14.78125\n",
      "Max snow depth: 1178.6\n",
      "Min solar_rad: 0.0\n",
      "Min ghi: 0.0\n"
     ]
    }
   ],
   "source": [
    "# print max values for solar_rad and ghi\n",
    "\n",
    "print(\"Max solar_rad:\", df_all['solar_rad'].max())\n",
    "print(\"Max ghi:\", df_all['ghi'].max())\n",
    "print(\"Max temp:\", df_all['temp'].max())\n",
    "print(\"Max precip:\", df_all['precip'].max())\n",
    "print(\"Max snow depth:\", df_all['snow_depth'].max())\n",
    "\n",
    "# min values\n",
    "print(\"Min solar_rad:\", df_all['solar_rad'].min())\n",
    "print(\"Min ghi:\", df_all['ghi'].min())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
